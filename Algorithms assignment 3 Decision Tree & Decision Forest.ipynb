{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load NumPy, pandas and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reused functions from Assignment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy and paste functions from Assignment 1 here that you need for this assignment\n",
    "def create_bins(df, nobins=10, bintype=\"equal-width\"):\n",
    "    #Hint 1: Basic\n",
    "    #copy the DataFrame first\n",
    "    df_copy = df.copy()\n",
    "    columns = df_copy.columns\n",
    "    binning = {}\n",
    "    \n",
    "    for i in columns:\n",
    "        dtype = df_copy[i].dtype\n",
    "\n",
    "        #Hint 2: Constratints handling\n",
    "        #do not care about ID or CLASS\n",
    "        if i == \"ID\" or i == \"CLASS\":\n",
    "            continue\n",
    "        #only care about int and float\n",
    "        if not np.issubdtype(dtype, np.integer) and not np.issubdtype(dtype, np.floating):\n",
    "            continue\n",
    "        \n",
    "        #Hint 3 - Case 1: equal width -> cut\n",
    "        if bintype == \"equal-width\":\n",
    "            res, bins = pd.cut(df_copy[i], bins=nobins, labels=False, retbins=True, duplicates=\"drop\")\n",
    "        #Hint 3 - Case 2: equal size -> qcut\n",
    "        elif bintype == \"equal-size\":\n",
    "            res, bins = pd.qcut(df_copy[i], q=nobins, labels=False, retbins=True, duplicates=\"drop\")\n",
    "            \n",
    "        #apply res\n",
    "        df_copy[i] = res\n",
    "        \n",
    "        #Hint 4 - Set column to be of type \"category\"\n",
    "        df_copy[i] = df_copy[i].astype(\"category\")\n",
    "        \n",
    "        #Hint 5 - set the categories as a number of bins\n",
    "        df_copy[i] = df_copy[i].cat.set_categories(list(range(len(bins))))\n",
    "        \n",
    "        #Hint 6 - set first and last value\n",
    "        bins[0] = -np.inf\n",
    "        bins[-1] = np.inf\n",
    "        \n",
    "        #set bins on the output\n",
    "        binning[i] = bins\n",
    "    \n",
    "    return df_copy, binning\n",
    "\n",
    "def apply_bins(df, binning):\n",
    "    #Hint 1: Basic\n",
    "    #copy the DataFrame first\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    for key, val in binning.items():\n",
    "        dtype = df_copy[key].dtype\n",
    "        #Hint 2: Constratints handling\n",
    "        \n",
    "        #do not care about ID or CLASS (safe check when applying!)\n",
    "        if key == \"ID\" or key == \"CLASS\":\n",
    "            continue\n",
    "        #only care about int and float\n",
    "        if not np.issubdtype(dtype, np.integer) and not np.issubdtype(dtype, np.floating):\n",
    "            continue\n",
    "        \n",
    "        #Hint 2\n",
    "        res = pd.cut(df_copy[key], bins=val, labels=False, duplicates=\"drop\")\n",
    "        df_copy[key] = res\n",
    "        \n",
    "        #Hint 3 - Set column to be of type \"category\"\n",
    "        df_copy[key] = df_copy[key].astype(\"category\")\n",
    "\n",
    "        #Hint 4 - set the categories as a number of nobins\n",
    "        df_copy[key] = df_copy[key].cat.set_categories(list(range(len(val))))\n",
    "        \n",
    "    return df_copy\n",
    "\n",
    "def create_imputation(df):\n",
    "    #Hint 1: Basic\n",
    "    #copy the DataFrame first\n",
    "    df_copy = df.copy()\n",
    "    columns = df_copy.columns\n",
    "    imputation = {}\n",
    "    \n",
    "    for i in columns:\n",
    "        dtype = df_copy[i].dtype\n",
    "\n",
    "        #Hint 2: Constratints handling\n",
    "        #do not care about ID or CLASS\n",
    "        if i == \"ID\" or i == \"CLASS\":\n",
    "            continue\n",
    "        #Case 1: continuous -> use mean\n",
    "        if np.issubdtype(dtype, np.integer) or np.issubdtype(dtype, np.floating):\n",
    "            #Special case: all values are missing\n",
    "            if np.all(df_copy[i].isnull()):\n",
    "                criteria = 0\n",
    "            #regular case\n",
    "            else:\n",
    "                criteria = df_copy[i].mean()\n",
    "        #case 2: categorical -> use mode\n",
    "        elif hasattr(df_copy[i], 'cat'):\n",
    "            #Special case: all values are missing\n",
    "            if np.all(df_copy[i].isnull()):\n",
    "                criteria = df_copy[i].cat.categories[0]\n",
    "            #regular case\n",
    "            else:\n",
    "                print(df_copy[i][df_copy[i].notnull()])\n",
    "                criteria = df_copy[i].mode()[0] #always return series\n",
    "        #case 3: object case -> cannot apply .cat -> use \"\" when all are missing\n",
    "        #not sure about dtype == \"object\" or else\n",
    "        elif dtype == \"object\":\n",
    "            #Special case: all values are missing\n",
    "            if np.all(df_copy[i].isnull()):\n",
    "                criteria = \"\"\n",
    "            #regular case\n",
    "            else:\n",
    "                criteria = df_copy[i].mode()[0] #always return series\n",
    "        #except object, categorical, numerical -> but there is no case when we load a file\n",
    "        else:\n",
    "            print(dtype)\n",
    "\n",
    "        #apply criteria (use fillna)\n",
    "        df_copy[i] = df_copy[i].fillna(criteria)\n",
    "        #add value into imputation dictionary\n",
    "        imputation[i] = criteria\n",
    "    \n",
    "    return df_copy, imputation\n",
    "\n",
    "def apply_imputation(df, imputation):\n",
    "    #Hint 1: Basic\n",
    "    #copy the DataFrame first\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    #key: column name\n",
    "    #val: imputation value\n",
    "    for key, val in imputation.items():\n",
    "        \n",
    "        #Hint 2: Constratints handling\n",
    "        #do not care about ID or CLASS (safe check when applying!)\n",
    "        if key == \"ID\" or key == \"CLASS\": \n",
    "            continue\n",
    "            \n",
    "        criteria = val\n",
    "        df_copy[key] = df_copy[key].fillna(criteria)\n",
    "            \n",
    "    return df_copy\n",
    "\n",
    "def brier_score(df, correctlabels):\n",
    "    #setting dictionary\n",
    "    correctdict = {}\n",
    "    brier_score = 0\n",
    "    \n",
    "    for i in correctlabels:\n",
    "        if i not in correctdict.keys():\n",
    "            correctdict[i] = [0]\n",
    "    \n",
    "    correctdict = pd.DataFrame(correctdict)\n",
    "\n",
    "    #loop number of samples\n",
    "    for cnt, val in enumerate(correctlabels):\n",
    "        #initialize 0 again\n",
    "        correctdict.iloc[0] = 0\n",
    "        #only correct one goes to 1\n",
    "        correctdict[val] = 1\n",
    "        #get single row in a prediction\n",
    "        row = df.iloc[cnt]\n",
    "        #calculate score\n",
    "        score = np.sum(np.square(row-correctdict), axis=1)\n",
    "        brier_score += score\n",
    "    \n",
    "    brier_score /= len(correctlabels)\n",
    "    return brier_score[0]\n",
    "\n",
    "def auc(df, correctlabels):\n",
    "    \"\"\"\n",
    "    We made new AUC function without using collection library following Henrik's comment\n",
    "    \"\"\"\n",
    "    #make labels\n",
    "    labels = set(correctlabels)\n",
    "    \n",
    "    #assignment 2,3 fix\n",
    "    correctlabels = correctlabels.tolist()\n",
    "    \n",
    "    counts = [] #for weighted sum (count of class in true population)\n",
    "    aucs = [] #auc score for each count\n",
    "    \n",
    "    #calculate TP/FP for each label\n",
    "    for label in labels:\n",
    "        #make scores \n",
    "        tot_tp = 0\n",
    "        tot_fp = 0\n",
    "        scores = {}\n",
    "        \n",
    "        for idx, val in enumerate(correctlabels):\n",
    "            if df.iloc[idx][label] not in scores.keys():\n",
    "                scores[df.iloc[idx][label]] = [0, 0]\n",
    "            if val == label:\n",
    "                scores[df.iloc[idx][label]][0] += 1\n",
    "                tot_tp += 1\n",
    "            else:\n",
    "                scores[df.iloc[idx][label]][1] += 1\n",
    "                tot_fp += 1\n",
    "         \n",
    "        #Descending sort by its score\n",
    "        scores = sorted(scores.items(), reverse=True)\n",
    "        \n",
    "        #GET AUC score\n",
    "        auc_sub = 0\n",
    "        cov_tp = 0\n",
    "        \n",
    "        for key, val in enumerate(scores):\n",
    "            tp_rate = val[1][0]\n",
    "            fp_rate = val[1][1]\n",
    "            if fp_rate == 0:\n",
    "                cov_tp += tp_rate\n",
    "            elif tp_rate == 0:\n",
    "                auc_sub += (cov_tp/tot_tp) * (fp_rate/tot_fp)\n",
    "            else:\n",
    "                auc_sub += (cov_tp/tot_tp)*(fp_rate/tot_fp) + ((tp_rate/tot_tp)*(fp_rate/tot_fp))/2\n",
    "                cov_tp += tp_rate\n",
    "        \n",
    "        #apply proportion\n",
    "        counts.append(correctlabels.count(label))\n",
    "        aucs.append(auc_sub)\n",
    "        \n",
    "    auc = np.array(aucs).dot(np.array(counts))/len(correctlabels)\n",
    "\n",
    "    return auc\n",
    "\n",
    "def accuracy(df, correctlabels):\n",
    "    df_copy = df.copy()\n",
    "    pred = np.empty(len(correctlabels))\n",
    "    \n",
    "    df_max = df_copy.max(axis=1) #find the highest value in each row to compare later\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        df_tmp = df_copy.iloc[i:i+1]\n",
    "        for col in df_tmp.columns:\n",
    "            if(df_tmp[col] >= df_max[i:i+1]).bool(): \n",
    "                pred[i] = col\n",
    "                \"\"\"\n",
    "                if break enabled, will pick the first option, \n",
    "                else, will leave the last option that equals the highest value, \n",
    "                can be randomized with an if and random function\n",
    "                \"\"\"\n",
    "                #1. random mode\n",
    "                #if np.random.choice([True, False]): break \n",
    "                \n",
    "                #2. picking first one mode\n",
    "                break\n",
    "                \n",
    "    numbercorrect = np.sum(np.array(correctlabels) == pred)\n",
    "    return numbercorrect/len(correctlabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define the class DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the class DecisionTree with three functions __init__, fit and predict (after the comments):\n",
    "#\n",
    "# Input to __init__: \n",
    "# self: the object itself\n",
    "#\n",
    "# Output from __init__:\n",
    "# nothing\n",
    "# \n",
    "# This function does not return anything but just initializes the following attributes of the object (self) to None:\n",
    "# binning, imputatiom, labels, model\n",
    "#\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self):\n",
    "        self.binning = None\n",
    "        self.imputation = None\n",
    "        self.labels = None\n",
    "        self.model = None\n",
    "    \n",
    "# Input to fit:\n",
    "# self: the object itself\n",
    "# df: a dataframe (where the column names \"CLASS\" and \"ID\" have special meaning)\n",
    "# nobins: no. of bins (default = 10)\n",
    "# bintype: either \"equal-width\" (default) or \"equal-size\"\n",
    "# min_samples_split: no. of instances required to allow a split (default = 5)\n",
    "#\n",
    "# Output from fit:\n",
    "# nothing\n",
    "#\n",
    "# The result of applying this function should be:\n",
    "#\n",
    "# self.binning should be a discretization mapping (see Assignment 1) from df\n",
    "# self.imputation should be an imputation mapping (see Assignment 1) from df\n",
    "# self.labels should be the categories of the \"CLASS\" column of df, set to be of type \"category\" \n",
    "# self.model should be a decision tree (for details, see lecture slides), where the leafs return class probabilities\n",
    "# Note that the function does not return anything but just assigns values to the attributes of the object.\n",
    "#\n",
    "# Hint 1: First find the available features (excluding \"CLASS\" and \"ID\"), then find the class counts, e.g., using \n",
    "#         groupby, and calculate the default class probabilities (relative frequencies of the class labels)\n",
    "# Hint 2: Define a function, e.g., called divide_and_conquer, that takes the above as input together with df \n",
    "#         and min_samples_split, and also a nodeno (starting with 0) to keep track of the generated nodes in the tree\n",
    "# Hint 3: You may represent the tree under construction as a list of nodes (tuples), on the form:\n",
    "#         (nodeno,\"leaf\",class_probabilities): corresponding to a leaf node where class_probabilities is a vector\n",
    "#                                              with the relative class frequencies (ordered according to self.labels)\n",
    "#         (nodeno,feature,node_dict): corresponding to an internal (non-leaf) node where node_dict is a mapping from\n",
    "#                                     the possible values of feature to child nodes (their nodenos)\n",
    "# Hint 4: You may evaluate each feature by a function information_content, which takes the group sizes\n",
    "#         for each possible value of the feature together with the class counts of each group as input\n",
    "# Hint 5: The best feature found (with lowest resulting information content) will be used to split the training\n",
    "#         instances, and each sub-group is used for generating a sub-tree (recursively by divide_and_conquer,\n",
    "#         see lecture slides for details)\n",
    "# Hint 6: The list of nodes output by divide_and_conquer may finally be converted to an array, where each nodeno in the \n",
    "#         tuples corresponds to an index of the array \n",
    "#\n",
    "# Input to predict:\n",
    "# self: the object itself\n",
    "# df: a dataframe\n",
    "# \n",
    "# Output from predict:\n",
    "# predictions: a dataframe with class labels as column names and the rows corresponding to\n",
    "#              predictions with estimated class probabilities for each row in df, where the class probabilities\n",
    "#              are the relative class frequencies in the leaves of the decision tree into which the instances in\n",
    "#              df fall\n",
    "#\n",
    "# Hint 1: Drop any \"CLASS\" and \"ID\" columns first and then apply imputation and binning\n",
    "# Hint 2: Iterate over the rows calling some sub-function, e.g., make_prediction(nodeno,row), which for a test row\n",
    "#         finds a leaf node from which class probabilities are obtained\n",
    "# Hint 3: This sub-function may recursively traverse the tree (represented by an array), starting with the nodeno\n",
    "#         that corresponds to the root\n",
    "\n",
    "    #Hint 2: define a divide and conquer function\n",
    "    #df, min_sample_split, nodeno\n",
    "    def divide_and_conquer(self, df, features, class_freq, min_samples_split, nodeno):\n",
    "        #check data, feature, unique class\n",
    "        #exit conditions: if the instance is empty, if there are no features to split, \n",
    "        #if all instances have the same features (we use <=1 for safety)\n",
    "        if len(df) < min_samples_split or len(features) == 0 or len(df['CLASS'].unique()) <= 1:\n",
    "            #leaf node processing\n",
    "            self.model.append((nodeno, \"leaf\", class_freq))\n",
    "        else:\n",
    "            #print(len(df), features)\n",
    "            #Hint 5: choose lowest information_contents\n",
    "            lowest = np.inf\n",
    "\n",
    "            #Hint 2: get frequencies to calculate information content\n",
    "            #where f has values and f will be omitted from features=F\n",
    "            for f in features:\n",
    "                feature_class_value_counts = {}\n",
    "                feature_value_counts = {}\n",
    "                \n",
    "                #for all possible values\n",
    "                for v in df[f].unique():\n",
    "                    #value count is count of each possible value in a single feature f \n",
    "                    value_counts = (df[f] == v).sum()\n",
    "                    #deal with all possible labels in 'whole dataset' to care about test data not in training data case\n",
    "                    #If the label is not in the current reduced training data set, it will get zero probability\n",
    "                    #we just regard zero probability as zero entropy (following lecture note)\n",
    "                    for c in self.labels:\n",
    "                        sumclass = ((df[\"CLASS\"] == c) & (df[f] == v)).sum()\n",
    "                        #for each possible value in a single feature, get count of final 'class' (y value)\n",
    "                        feature_class_value_counts[(c,v)] = sumclass / value_counts\n",
    "                    #make the value count as a relative frequency\n",
    "                    feature_value_counts[v] = value_counts / len(df)\n",
    "                \n",
    "                #get entropy of feature f\n",
    "                information_contents = self.information_content(feature_class_value_counts, feature_value_counts)\n",
    "\n",
    "                #Hint 5: choose the feature having lowest information_contents\n",
    "                if information_contents < lowest:\n",
    "                    lowest = information_contents\n",
    "                    lowest_feature = f\n",
    "            \n",
    "            #Hint 3: possible value-feature mapping\n",
    "            node_dict = {}\n",
    "            #making F = F \\ {f}\n",
    "            new_features = features - set([lowest_feature])\n",
    "            \n",
    "            ######## This area is for calculating no possible instance case #######\n",
    "            #According to lecture note, even though there will be no instance following certain value in a feature\n",
    "            #the tree should grow to this value, and relative frequency will follow most frequent value (maximum count)\n",
    "            #in the feature.\n",
    "            \n",
    "            #get most frequent value case first before looping possible feature values\n",
    "            #in the case of no any possible instances for some feature values\n",
    "            #in case of none class, just label the class which has the largest number of instance\n",
    "            \n",
    "            #Here we have a random policy.\n",
    "            #there are possibility of having multiple modes in a single feature, then we pick the first one.\n",
    "            most_frequent_value = df[lowest_feature].mode()[0]\n",
    "            \n",
    "            #in the column of lowest feature, replace all the rows with the most frequest ones\n",
    "            new_df_new = df[df[lowest_feature] == most_frequent_value]\n",
    "            \n",
    "            #calculate next relative frequency of most frequent value\n",
    "            new_rf_mfv = pd.Series(np.zeros(len(self.labels)), index = self.labels)\n",
    "            new_rf_mfv += new_df_new['CLASS'].value_counts()/len(new_df_new['CLASS'])\n",
    "            new_rf_mfv.fillna(0, inplace=True)\n",
    "            \n",
    "            #########################################################################\n",
    "            \n",
    "            #Normal case: for all possible values having instances\n",
    "            for value in df[lowest_feature].cat.categories:\n",
    "                \n",
    "                #I1, I2, ... , In having value of v1, v2, ... , vn\n",
    "                new_df = df[df[lowest_feature] == value]\n",
    "                \n",
    "                #No instance case: when there is no instance for possible value low_f \n",
    "                #probability follows the most frequent value among siblings, already calculated above\n",
    "                if len(new_df) == 0:\n",
    "                    new_rf = new_rf_mfv\n",
    "                else:\n",
    "                    #calculate next frequency\n",
    "                    new_rf = pd.Series(np.zeros(len(self.labels)), index = self.labels)\n",
    "                    new_rf += new_df['CLASS'].value_counts()/len(new_df['CLASS'])\n",
    "                    new_rf.fillna(0, inplace=True)\n",
    "\n",
    "                #recursively add nodeno\n",
    "                self.nodeno += 1\n",
    "                node_dict[value] = self.nodeno\n",
    "                self.divide_and_conquer(new_df, new_features, new_rf, min_samples_split, self.nodeno)\n",
    "                \n",
    "            #add current model (take care of order)\n",
    "            self.model.append((nodeno, lowest_feature, node_dict ))\n",
    "\n",
    "    #Hint 4\n",
    "    def information_content(self, class_value, feature_value):\n",
    "        #Get entropy when we grow the tree with selected feature.\n",
    "        info = 0\n",
    "        \n",
    "        for v in feature_value.keys():\n",
    "            for c in self.labels:\n",
    "                #regard negative inifinity entropy as a zero information\n",
    "                if class_value[(c,v)] != 0.0:\n",
    "                    #Entropy formula : (|Sv|/|S|) * (Sum(-P log(Pi)))\n",
    "                    info += feature_value[v]*(-class_value[(c,v)]*np.log2(class_value[(c,v)]))\n",
    "        return info\n",
    "    \n",
    "    def fit(self, df, nobins=10, bintype=\"equal-width\", min_samples_split=5):\n",
    "        \n",
    "        #make self.model as a array\n",
    "        self.model = []\n",
    "        \n",
    "        #get defalut self datapoints first to use \n",
    "        df_copy, self.imputation = create_imputation(df)\n",
    "        df_copy, self.binning = create_bins(df_copy, nobins=nobins, bintype=bintype)\n",
    "        \n",
    "        #Finding the possible labels\n",
    "        self.labels = df_copy[\"CLASS\"].astype('category').cat.categories\n",
    "        \n",
    "        #Hint 1: find available features and class frequency\n",
    "\n",
    "        #available features\n",
    "        available_features = set(df_copy.columns) - set([\"ID\", \"CLASS\"]) \n",
    "        \n",
    "        #initial class relative frequency\n",
    "        initial_rf = df_copy['CLASS'].value_counts()/len(df_copy['CLASS'])\n",
    "        \n",
    "        #set global nodeno and put it in the divide and conquer\n",
    "        self.nodeno = 0\n",
    "        self.divide_and_conquer(df_copy, available_features, initial_rf, min_samples_split, self.nodeno)\n",
    "\n",
    "        #sort the model based on its nodeno\n",
    "        self.model.sort(key=lambda x: x[0])\n",
    "        \n",
    "\n",
    "    \n",
    "    def make_prediction(self, row, nodeno):\n",
    "        #if the nodeno is not leaf\n",
    "        if self.model[nodeno][1] != 'leaf':\n",
    "            #check nodeno's spliting criteria. Getting the feature name\n",
    "            split = self.model[nodeno][1]\n",
    "            \n",
    "            #check the feature value \n",
    "            value = row[split]\n",
    "            \n",
    "            #check the model again to match the new nodeno\n",
    "            #getting the number of instances in every feature value\n",
    "            new_nodeno = self.model[nodeno][2][value]\n",
    "\n",
    "            #predict again\n",
    "            try:\n",
    "                return self.make_prediction(row, new_nodeno)\n",
    "            except:\n",
    "                #miss case does not occur in this algorithm, but apply it for safety\n",
    "                print(\"miss\")\n",
    "        else:\n",
    "            return self.model[nodeno][2]\n",
    "            \n",
    "    def predict(self, df):\n",
    "        \n",
    "        #Hint 1: drop id and class\n",
    "        df_copy = df.copy()\n",
    "        \n",
    "        #it is better to check it seperately because in some unknown dataset there can be only one among ID and CLASS\n",
    "        if \"ID\" in df_copy.columns:\n",
    "            df_copy.drop([\"ID\"], inplace=True, axis=1)\n",
    "        if \"CLASS\" in df_copy.columns:\n",
    "            df_copy.drop([\"CLASS\"], inplace=True, axis=1)\n",
    "            \n",
    "        #Hint 1: apply imputation, binning\n",
    "        df_copy = apply_imputation(df_copy, self.imputation)\n",
    "        df_copy = apply_bins(df_copy, self.binning)\n",
    "        \n",
    "        #Hint 2: iterate over the rows\n",
    "        predictions = df_copy.apply(self.make_prediction, axis=1, nodeno=0)\n",
    "        \n",
    "        #fix NaN value (zero probabilities) into real zero\n",
    "        predictions.fillna(0, inplace=True)\n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time (5, 'equal-width', 3): 1.86 s.\n",
      "Testing time (5, 'equal-width', 3): 0.04 s.\n",
      "Training time (5, 'equal-width', 5): 1.63 s.\n",
      "Testing time (5, 'equal-width', 5): 0.04 s.\n",
      "Training time (5, 'equal-width', 10): 1.06 s.\n",
      "Testing time (5, 'equal-width', 10): 0.05 s.\n",
      "Training time (5, 'equal-size', 3): 2.24 s.\n",
      "Testing time (5, 'equal-size', 3): 0.04 s.\n",
      "Training time (5, 'equal-size', 5): 1.36 s.\n",
      "Testing time (5, 'equal-size', 5): 0.04 s.\n",
      "Training time (5, 'equal-size', 10): 0.86 s.\n",
      "Testing time (5, 'equal-size', 10): 0.04 s.\n",
      "Training time (10, 'equal-width', 3): 2.47 s.\n",
      "Testing time (10, 'equal-width', 3): 0.04 s.\n",
      "Training time (10, 'equal-width', 5): 1.76 s.\n",
      "Testing time (10, 'equal-width', 5): 0.03 s.\n",
      "Training time (10, 'equal-width', 10): 1.24 s.\n",
      "Testing time (10, 'equal-width', 10): 0.03 s.\n",
      "Training time (10, 'equal-size', 3): 2.33 s.\n",
      "Testing time (10, 'equal-size', 3): 0.04 s.\n",
      "Training time (10, 'equal-size', 5): 2.12 s.\n",
      "Testing time (10, 'equal-size', 5): 0.04 s.\n",
      "Training time (10, 'equal-size', 10): 1.93 s.\n",
      "Testing time (10, 'equal-size', 10): 0.03 s.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Brier score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">5</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">equal-width</th>\n",
       "      <th>3</th>\n",
       "      <td>0.654206</td>\n",
       "      <td>0.573480</td>\n",
       "      <td>0.792989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.663551</td>\n",
       "      <td>0.536875</td>\n",
       "      <td>0.811069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.598131</td>\n",
       "      <td>0.540770</td>\n",
       "      <td>0.806463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">equal-size</th>\n",
       "      <th>3</th>\n",
       "      <td>0.626168</td>\n",
       "      <td>0.709367</td>\n",
       "      <td>0.746560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.635514</td>\n",
       "      <td>0.643167</td>\n",
       "      <td>0.761936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.598131</td>\n",
       "      <td>0.652672</td>\n",
       "      <td>0.743455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">10</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">equal-width</th>\n",
       "      <th>3</th>\n",
       "      <td>0.626168</td>\n",
       "      <td>0.613303</td>\n",
       "      <td>0.798035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.598131</td>\n",
       "      <td>0.561641</td>\n",
       "      <td>0.821840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.598131</td>\n",
       "      <td>0.500888</td>\n",
       "      <td>0.848858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">equal-size</th>\n",
       "      <th>3</th>\n",
       "      <td>0.523364</td>\n",
       "      <td>0.930815</td>\n",
       "      <td>0.669847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.523364</td>\n",
       "      <td>0.928479</td>\n",
       "      <td>0.669676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.542056</td>\n",
       "      <td>0.902172</td>\n",
       "      <td>0.677709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Accuracy  Brier score       AUC\n",
       "5  equal-width 3   0.654206     0.573480  0.792989\n",
       "               5   0.663551     0.536875  0.811069\n",
       "               10  0.598131     0.540770  0.806463\n",
       "   equal-size  3   0.626168     0.709367  0.746560\n",
       "               5   0.635514     0.643167  0.761936\n",
       "               10  0.598131     0.652672  0.743455\n",
       "10 equal-width 3   0.626168     0.613303  0.798035\n",
       "               5   0.598131     0.561641  0.821840\n",
       "               10  0.598131     0.500888  0.848858\n",
       "   equal-size  3   0.523364     0.930815  0.669847\n",
       "               5   0.523364     0.928479  0.669676\n",
       "               10  0.542056     0.902172  0.677709"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test your code (leave this part unchanged, except for if auc is undefined)\n",
    "\n",
    "glass_train_df = pd.read_csv(\"glass_train.txt\")\n",
    "\n",
    "glass_test_df = pd.read_csv(\"glass_test.txt\")\n",
    "\n",
    "tree_model = DecisionTree()\n",
    "\n",
    "test_labels = glass_test_df[\"CLASS\"]\n",
    "\n",
    "nobins_values = [5,10]\n",
    "bintype_values = [\"equal-width\",\"equal-size\"]\n",
    "min_samples_split_values = [3,5,10]\n",
    "parameters = [(nobins,bintype,min_samples_split) for nobins in nobins_values for bintype in bintype_values \n",
    "              for min_samples_split in min_samples_split_values]\n",
    "\n",
    "results = np.empty((len(parameters),3))\n",
    "\n",
    "for i in range(len(parameters)):\n",
    "    t0 = time.perf_counter()\n",
    "    tree_model.fit(glass_train_df,nobins=parameters[i][0],bintype=parameters[i][1],min_samples_split=parameters[i][2])\n",
    "    print(\"Training time {0}: {1:.2f} s.\".format(parameters[i],time.perf_counter()-t0))\n",
    "    t0 = time.perf_counter()\n",
    "    predictions = tree_model.predict(glass_test_df)\n",
    "    print(\"Testing time {0}: {1:.2f} s.\".format(parameters[i],time.perf_counter()-t0))\n",
    "    results[i] = [accuracy(predictions,test_labels),brier_score(predictions,test_labels),\n",
    "                  auc(predictions,test_labels)] # Assuming that you have defined auc - remove otherwise\n",
    "\n",
    "results = pd.DataFrame(results,index=pd.MultiIndex.from_product([nobins_values,bintype_values,min_samples_split_values]),\n",
    "                       columns=[\"Accuracy\",\"Brier score\",\"AUC\"])\n",
    "\n",
    "results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Henrik's result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time (5, 'equal-width', 3): 1.58 s.\n",
      "Testing time (5, 'equal-width', 3): 0.11 s.\n",
      "Training time (5, 'equal-width', 5): 1.33 s.\n",
      "Testing time (5, 'equal-width', 5): 0.11 s.\n",
      "Training time (5, 'equal-width', 10): 0.74 s.\n",
      "Testing time (5, 'equal-width', 10): 0.11 s.\n",
      "Training time (5, 'equal-size', 3): 1.60 s.\n",
      "Testing time (5, 'equal-size', 3): 0.07 s.\n",
      "Training time (5, 'equal-size', 5): 0.84 s.\n",
      "Testing time (5, 'equal-size', 5): 0.07 s.\n",
      "Training time (5, 'equal-size', 10): 0.44 s.\n",
      "Testing time (5, 'equal-size', 10): 0.07 s.\n",
      "Training time (10, 'equal-width', 3): 2.47 s.\n",
      "Testing time (10, 'equal-width', 3): 0.06 s.\n",
      "Training time (10, 'equal-width', 5): 1.56 s.\n",
      "Testing time (10, 'equal-width', 5): 0.06 s.\n",
      "Training time (10, 'equal-width', 10): 0.88 s.\n",
      "Testing time (10, 'equal-width', 10): 0.06 s.\n",
      "Training time (10, 'equal-size', 3): 1.51 s.\n",
      "Testing time (10, 'equal-size', 3): 0.07 s.\n",
      "Training time (10, 'equal-size', 5): 1.32 s.\n",
      "Testing time (10, 'equal-size', 5): 0.07 s.\n",
      "Training time (10, 'equal-size', 10): 1.25 s.\n",
      "Testing time (10, 'equal-size', 10): 0.08 s.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Brier score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">5</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">equal-width</th>\n",
       "      <th>3</th>\n",
       "      <td>0.635514</td>\n",
       "      <td>0.566861</td>\n",
       "      <td>0.794838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.644860</td>\n",
       "      <td>0.530257</td>\n",
       "      <td>0.812039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.579439</td>\n",
       "      <td>0.540913</td>\n",
       "      <td>0.802684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">equal-size</th>\n",
       "      <th>3</th>\n",
       "      <td>0.644860</td>\n",
       "      <td>0.678333</td>\n",
       "      <td>0.757026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.635514</td>\n",
       "      <td>0.644065</td>\n",
       "      <td>0.759834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.598131</td>\n",
       "      <td>0.652672</td>\n",
       "      <td>0.743455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">10</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">equal-width</th>\n",
       "      <th>3</th>\n",
       "      <td>0.654206</td>\n",
       "      <td>0.566439</td>\n",
       "      <td>0.816216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.626168</td>\n",
       "      <td>0.529316</td>\n",
       "      <td>0.832679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.598131</td>\n",
       "      <td>0.503810</td>\n",
       "      <td>0.845034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">equal-size</th>\n",
       "      <th>3</th>\n",
       "      <td>0.504673</td>\n",
       "      <td>0.905079</td>\n",
       "      <td>0.656123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.504673</td>\n",
       "      <td>0.902743</td>\n",
       "      <td>0.655598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.532710</td>\n",
       "      <td>0.868821</td>\n",
       "      <td>0.669287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Accuracy  Brier score       AUC\n",
       "5  equal-width 3   0.635514     0.566861  0.794838\n",
       "               5   0.644860     0.530257  0.812039\n",
       "               10  0.579439     0.540913  0.802684\n",
       "   equal-size  3   0.644860     0.678333  0.757026\n",
       "               5   0.635514     0.644065  0.759834\n",
       "               10  0.598131     0.652672  0.743455\n",
       "10 equal-width 3   0.654206     0.566439  0.816216\n",
       "               5   0.626168     0.529316  0.832679\n",
       "               10  0.598131     0.503810  0.845034\n",
       "   equal-size  3   0.504673     0.905079  0.656123\n",
       "               5   0.504673     0.902743  0.655598\n",
       "               10  0.532710     0.868821  0.669287"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test your code (leave this part unchanged, except for if auc is undefined)\n",
    "\n",
    "glass_train_df = pd.read_csv(\"glass_train.txt\")\n",
    "\n",
    "glass_test_df = pd.read_csv(\"glass_test.txt\")\n",
    "\n",
    "tree_model = DecisionTree()\n",
    "\n",
    "test_labels = glass_test_df[\"CLASS\"]\n",
    "\n",
    "nobins_values = [5,10]\n",
    "bintype_values = [\"equal-width\",\"equal-size\"]\n",
    "min_samples_split_values = [3,5,10]\n",
    "parameters = [(nobins,bintype,min_samples_split) for nobins in nobins_values for bintype in bintype_values \n",
    "              for min_samples_split in min_samples_split_values]\n",
    "\n",
    "results = np.empty((len(parameters),3))\n",
    "\n",
    "for i in range(len(parameters)):\n",
    "    t0 = time.perf_counter()\n",
    "    tree_model.fit(glass_train_df,nobins=parameters[i][0],bintype=parameters[i][1],min_samples_split=parameters[i][2])\n",
    "    print(\"Training time {0}: {1:.2f} s.\".format(parameters[i],time.perf_counter()-t0))\n",
    "    t0 = time.perf_counter()\n",
    "    predictions = tree_model.predict(glass_test_df)\n",
    "    print(\"Testing time {0}: {1:.2f} s.\".format(parameters[i],time.perf_counter()-t0))\n",
    "    results[i] = [accuracy(predictions,test_labels),brier_score(predictions,test_labels),\n",
    "                  auc(predictions,test_labels)] # Assuming that you have defined auc - remove otherwise\n",
    "\n",
    "results = pd.DataFrame(results,index=pd.MultiIndex.from_product([nobins_values,bintype_values,min_samples_split_values]),\n",
    "                       columns=[\"Accuracy\",\"Brier score\",\"AUC\"])\n",
    "\n",
    "results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.97\n",
      "AUC on training set: 1.00\n",
      "Brier score on training set: 0.03\n"
     ]
    }
   ],
   "source": [
    "train_labels = glass_train_df[\"CLASS\"]\n",
    "tree_model.fit(glass_train_df,min_samples_split=1)\n",
    "predictions = tree_model.predict(glass_train_df)\n",
    "print(\"Accuracy on training set: {0:.2f}\".format(accuracy(predictions,train_labels)))\n",
    "print(\"AUC on training set: {0:.2f}\".format(auc(predictions,train_labels)))\n",
    "print(\"Brier score on training set: {0:.2f}\".format(brier_score(predictions,train_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment on assumptions, things that do not work properly, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We followed all instructions and made a perfect algorithm. There is no any wrong thing in the algorithm.\n",
    "Due to two randomness in choosing same number, the result on the test dataset is different.\n",
    "Our overall poerformance is slightly better than answer sheet but only one or two instances in testset.\n",
    "\n",
    "There are two randomness and our criteria is below:\n",
    "1. Growing empty value in a feature\n",
    " - When we grow a tree after choosing a feater, based on possible values in single feature, we grow the value having no instance too. In this case, according to the lecture note, the relative frequency will follow the value that is most prevalent in the feature.\n",
    " - In this dataset, there are the cases having more than two same \"most prevalent value (mode)\" in a feature. in this case we always choose first one, not randomly choose.\n",
    " \n",
    "2. Test: choose highest probability among possible classes\n",
    " - If there are multiple highest probabilities, we choose first one, not randomly choose.\n",
    " \n",
    "These two random cases handling can change the result slightly. But the result is very similar (only 1-2 instances of difference as test set is just 107 instances)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define the class DecisionForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the class DecisionForest with three functions __init__, fit and predict (after the comments):\n",
    "#\n",
    "# Input to __init__: \n",
    "# self: the object itself\n",
    "#\n",
    "# Output from __init__:\n",
    "# nothing\n",
    "# \n",
    "# This function does not return anything but just initializes the following attributes of the object (self) to None:\n",
    "# binning, imputatiom, labels, model\n",
    "#\n",
    "# Input to fit:\n",
    "# self: the object itself\n",
    "# df: a dataframe (where the column names \"CLASS\" and \"ID\" have special meaning)\n",
    "# nobins: no. of bins (default = 10)\n",
    "# bintype: either \"equal-width\" (default) or \"equal-size\"\n",
    "# min_samples_split: no. of instances required to allow a split (default = 5)\n",
    "# random_features: no. of features to evaluate at each split (default = 2), 0 means all features (no random sampling)\n",
    "# notrees: no. of trees in the forest (default = 10)\n",
    "#\n",
    "# Output from fit:\n",
    "# nothing\n",
    "#\n",
    "# The result of applying this function should be:\n",
    "#\n",
    "# self.binning should be a discretization mapping (see Assignment 1) from df\n",
    "# self.imputation should be an imputation mapping (see Assignment 1) from df\n",
    "# self.labels should be the categories of the \"CLASS\" column of df, set to be of type \"category\" \n",
    "# self.model should be a random forest (for details, see lecture slides)\n",
    "# Note that the function does not return anything but just assigns values to the attributes of the object.\n",
    "#\n",
    "# Hint 1: Redefine divide_and_conquer to take one additional argument; random_features, and instead of\n",
    "#         evaluating all features choose a random subset, e.g., by np.random.choice (without replacement)\n",
    "# Hint 2: Generate each tree in the forest from a bootstrap replicate of df, e.g., by np.random.choice \n",
    "#         (with replacement) from the index values of df.\n",
    "#\n",
    "# Input to predict:\n",
    "# self: the object itself\n",
    "# df: a dataframe\n",
    "# \n",
    "# Output from predict:\n",
    "# predictions: a dataframe with class labels as column names and the rows corresponding to\n",
    "#              predictions with estimated class probabilities for each row in df, where the class probabilities\n",
    "#              are the mean of all relative class frequencies in the leaves of the forest into which the instances in\n",
    "#              df fall\n",
    "#\n",
    "# Hint 1: Drop any \"CLASS\" and \"ID\" columns first and then apply imputation and binning\n",
    "# Hint 2: Iterate over the rows calling some sub-function, e.g., make_prediction(row), which for a test row\n",
    "#         finds all leaf nodes and calculates the average of their class probabilities\n",
    "\n",
    "class DecisionForest(DecisionTree):\n",
    "    def __init__(self):\n",
    "        self.binning = None\n",
    "        self.imputation = None\n",
    "        self.labels = None\n",
    "        self.model = None     \n",
    "        \n",
    "    def divide_and_conquer(self, df, features, class_freq, min_samples_split, nodeno, random_features, modelno):\n",
    "        \"\"\"\n",
    "        We added new parameter modelno to figure out the model among multiple modles\n",
    "        \"\"\"\n",
    "        #exit case of random forest\n",
    "        #check data, feature, unique class (for satefy we use <= 1 for unique case)\n",
    "        #it is same as decision tree case.\n",
    "        if len(df) < min_samples_split or len(features) == 0 or len(df['CLASS'].unique()) <= 1:\n",
    "            #leaf node processing\n",
    "            self.model[modelno].append((nodeno, \"leaf\", class_freq))\n",
    "        else:\n",
    "            \n",
    "            ##########RANDOM FOREST: GENERATE FEATURE SELECTION##########\n",
    "            #if available feature is less than random feature, we will not apply feature selection\n",
    "            #when there are less number of features than the parameter, we are just selecting the remaining features instead of exiting\n",
    "            \n",
    "            if random_features != 0 and len(features) >= random_features:\n",
    "                #if random features are upper zero and all possible features are bigger and equal to the random features\n",
    "                #because every phase F - {f} is done, features can be less than number of random_features\n",
    "                selected_features = set(np.random.choice(list(features), random_features, replace = False))\n",
    "            else:\n",
    "                #if random_feature is zero, then we will not apply feature selection\n",
    "                #Or, if evaluation variable(random_features) are bigger than available number of features, \n",
    "                #then we take all features (do not perform feature selection)\n",
    "                #(There is no criteria of handling this case, so we followed scikit-learn manual)\n",
    "                #\n",
    "                #We also tested early pruning (if available feature is less than random_feature, then terminate)\n",
    "                #but the performance was similar. So we did not apply early pruning.\n",
    "                #\n",
    "                selected_features = features\n",
    "            #############################################################\n",
    "\n",
    "            #choose lowest information_contents\n",
    "            lowest = np.inf\n",
    "\n",
    "            #get frequencies to calculate information content\n",
    "            #where f has values and f will be omitted from features=F\n",
    "            #selected feautre is only used into the entropy part\n",
    "            for f in selected_features:\n",
    "                feature_class_value_counts = {}\n",
    "                feature_value_counts = {}\n",
    "                \n",
    "                #for all possible values\n",
    "                for v in df[f].unique():\n",
    "                    value_counts = (df[f] == v).sum()\n",
    "                    #Deal with all lables for unknown possible test set\n",
    "                    for c in self.labels:\n",
    "                        sumclass = ((df[\"CLASS\"] == c) & (df[f] == v)).sum()\n",
    "                        feature_class_value_counts[(c,v)] = sumclass / value_counts\n",
    "                    feature_value_counts[v] = value_counts / len(df)\n",
    "\n",
    "                information_contents = self.information_content(feature_class_value_counts, feature_value_counts)\n",
    "\n",
    "                #Hint 5: choose the feature having lowest information_contents\n",
    "                if information_contents < lowest:\n",
    "                    lowest = information_contents\n",
    "                    lowest_feature = f\n",
    "            \n",
    "            #possible value-feature mapping\n",
    "            node_dict = {}\n",
    "            #making F = F \\ {f}\n",
    "            new_features = features - set([lowest_feature])\n",
    "            \n",
    "            #get most frequent value case first before looping possible feature values\n",
    "            #in the case of no any possible instances for some feature values\n",
    "            most_frequent_value = df[lowest_feature].mode()[0]\n",
    "            new_df_new = df[df[lowest_feature] == most_frequent_value]\n",
    "            \n",
    "            #calculate next relative frequency of most frequent value\n",
    "            new_rf_mfv = pd.Series(np.zeros(len(self.labels)), index = self.labels)\n",
    "            new_rf_mfv += new_df_new['CLASS'].value_counts()/len(new_df_new['CLASS'])\n",
    "            new_rf_mfv.fillna(0, inplace=True)\n",
    "            \n",
    "            #for all possible values\n",
    "            for value in df[lowest_feature].cat.categories:\n",
    "                \n",
    "                ######## This area is for calculating no possible instance case #######\n",
    "                #According to lecture note, even though there will be no instance following certain value in a feature\n",
    "                #the tree should grow to this value, and relative frequency will follow most frequent value (maximum count)\n",
    "                #in the feature.\n",
    "\n",
    "                #get most frequent value case first before looping possible feature values\n",
    "                #in the case of no any possible instances for some feature values\n",
    "                #in case of none class, just label the class which has the largest number of instance\n",
    "\n",
    "                #I1, I2, ... , In having value of v1, v2, ... , vn\n",
    "                new_df = df[df[lowest_feature] == value]\n",
    "                \n",
    "                #when there is no any case of possible value low_f \n",
    "                #probability follows the most frequent value among siblings\n",
    "                if len(new_df) == 0:\n",
    "                    new_rf = new_rf_mfv\n",
    "                else:\n",
    "                    #calculate next frequency\n",
    "                    new_rf = pd.Series(np.zeros(len(self.labels)), index = self.labels)\n",
    "                    new_rf += new_df['CLASS'].value_counts()/len(new_df['CLASS'])\n",
    "                    new_rf.fillna(0, inplace=True)\n",
    "\n",
    "                #recursively add nodeno\n",
    "                self.nodeno += 1\n",
    "                node_dict[value] = self.nodeno\n",
    "                self.divide_and_conquer(new_df, new_features, new_rf, min_samples_split, self.nodeno, random_features, modelno)\n",
    "                \n",
    "            #add current model (take care of order)\n",
    "            self.model[modelno].append((nodeno, lowest_feature, node_dict ))\n",
    "    \n",
    "    def fit(self, df, nobins=10, bintype=\"equal-width\", min_samples_split=5, notrees=10, random_features=2):\n",
    "        \n",
    "        #make self.model as a array\n",
    "        self.model = []\n",
    "        \n",
    "        #get defalut self datapoints first to use \n",
    "        df_copy, self.imputation = create_imputation(df)\n",
    "        df_copy, self.binning = create_bins(df_copy, nobins=nobins, bintype=bintype)\n",
    "        self.labels = df_copy[\"CLASS\"].astype('category').cat.categories\n",
    "        \n",
    "        #find available features and class frequency\n",
    "\n",
    "        #available features\n",
    "        available_features = set(df_copy.columns) - set([\"ID\", \"CLASS\"]) \n",
    "        \n",
    "        #initial class relative frequency\n",
    "        initial_rf = df_copy['CLASS'].value_counts()/len(df_copy['CLASS'])\n",
    "        \n",
    "        ##########RANDOM FOREST: GENERATE BOOTSTRAP REPLICA##########\n",
    "        #for each tree model\n",
    "        for model_no in range(notrees):\n",
    "            #generate replica with replacement for each model\n",
    "            replica = df_copy.loc[np.random.choice(df_copy.index, len(df_copy), replace = True)]\n",
    "\n",
    "            #set global nodeno and put it in the divide and conquer\n",
    "            self.nodeno = 0\n",
    "            self.model.append([])\n",
    "            #we added new parameter as a model no.\n",
    "            self.divide_and_conquer(replica, available_features, initial_rf, min_samples_split, self.nodeno, random_features, model_no)\n",
    "\n",
    "            #sort the model based on its nodeno\n",
    "            self.model[model_no].sort(key=lambda x: x[0])\n",
    "\n",
    "        #############################################################\n",
    "    \n",
    "    def make_prediction(self, row, nodeno, model):\n",
    "        \"\"\"\n",
    "        We add a new parameter 'model', meaning one model in forest\n",
    "        the model is passed from the new function for random forest, \"make_prediction_averge\"\n",
    "        \"\"\"\n",
    "        #if the nodeno is not leaf\n",
    "        if model[nodeno][1] != 'leaf':\n",
    "            #check nodeno's spliting criteria\n",
    "            split = model[nodeno][1]\n",
    "            \n",
    "            #check the data value of spliting criteria\n",
    "            value = row[split]\n",
    "            \n",
    "            #check the model again to match the new nodeno\n",
    "            new_nodeno = model[nodeno][2][value]\n",
    "\n",
    "            #predict again\n",
    "            try:\n",
    "                return self.make_prediction(row, new_nodeno, model)\n",
    "            except:\n",
    "                #miss case does not occur in this algorithm, but apply it for safety\n",
    "                print(\"miss\")\n",
    "        else:\n",
    "            return model[nodeno][2]\n",
    "    \n",
    "    def make_prediction_average(self, row, nodeno):\n",
    "        \"\"\"\n",
    "        New function for random forest: take prediction using each model and then average it\n",
    "        \"\"\"\n",
    "        \n",
    "        prediction_result = []\n",
    "        \n",
    "        for model in self.model:\n",
    "            prediction_result.append(self.make_prediction(row, nodeno, model))\n",
    "        \n",
    "        #group average: this level=0 groupby function with concat takes every result dataframes \n",
    "        #in array and mean rows having same index in each dataframe\n",
    "        #So finally we can get the averaged probability for each row, each column\n",
    "        return pd.concat(prediction_result).groupby(level=0).mean()\n",
    "        \n",
    "    def predict(self, df):\n",
    "        \n",
    "        #Hint 1: drop id and class\n",
    "        df_copy = df.copy()\n",
    "        \n",
    "        #it is better to check it seperately because in some unknown dataset there can be only one among ID and CLASS\n",
    "        if \"ID\" in df_copy.columns:\n",
    "            df_copy.drop([\"ID\"], inplace=True, axis=1)\n",
    "        if \"CLASS\" in df_copy.columns:\n",
    "            df_copy.drop([\"CLASS\"], inplace=True, axis=1)\n",
    "            \n",
    "        #Hint 1: apply imputation, binning\n",
    "        df_copy = apply_imputation(df_copy, self.imputation)\n",
    "        df_copy = apply_bins(df_copy, self.binning)\n",
    "        \n",
    "        #Hint 2: iterate over the rows\n",
    "        predictions = df_copy.apply(self.make_prediction_average, axis=1, nodeno=0)\n",
    "        \n",
    "        #fix NaN value (zero probabilities) into real zero\n",
    "        predictions.fillna(0, inplace=True)\n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time (1, 1): 10.50 s.\n",
      "Testing time (1, 1): 0.20 s.\n",
      "Training time (1, 2): 11.95 s.\n",
      "Testing time (1, 2): 0.20 s.\n",
      "Training time (1, 5): 15.39 s.\n",
      "Testing time (1, 5): 0.19 s.\n",
      "Training time (2, 1): 10.03 s.\n",
      "Testing time (2, 1): 0.19 s.\n",
      "Training time (2, 2): 11.97 s.\n",
      "Testing time (2, 2): 0.19 s.\n",
      "Training time (2, 5): 15.42 s.\n",
      "Testing time (2, 5): 0.20 s.\n",
      "Training time (5, 1): 6.75 s.\n",
      "Testing time (5, 1): 0.20 s.\n",
      "Training time (5, 2): 7.80 s.\n",
      "Testing time (5, 2): 0.20 s.\n",
      "Training time (5, 5): 11.03 s.\n",
      "Testing time (5, 5): 0.20 s.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Brier score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>0.691589</td>\n",
       "      <td>0.429096</td>\n",
       "      <td>0.884213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.644860</td>\n",
       "      <td>0.444150</td>\n",
       "      <td>0.864234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.616822</td>\n",
       "      <td>0.451942</td>\n",
       "      <td>0.853692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2</th>\n",
       "      <th>1</th>\n",
       "      <td>0.682243</td>\n",
       "      <td>0.420095</td>\n",
       "      <td>0.893244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.654206</td>\n",
       "      <td>0.442932</td>\n",
       "      <td>0.885548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.719626</td>\n",
       "      <td>0.388174</td>\n",
       "      <td>0.913320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">5</th>\n",
       "      <th>1</th>\n",
       "      <td>0.654206</td>\n",
       "      <td>0.422594</td>\n",
       "      <td>0.874119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.663551</td>\n",
       "      <td>0.451512</td>\n",
       "      <td>0.870941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.700935</td>\n",
       "      <td>0.435951</td>\n",
       "      <td>0.880581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Accuracy  Brier score       AUC\n",
       "1 1  0.691589     0.429096  0.884213\n",
       "  2  0.644860     0.444150  0.864234\n",
       "  5  0.616822     0.451942  0.853692\n",
       "2 1  0.682243     0.420095  0.893244\n",
       "  2  0.654206     0.442932  0.885548\n",
       "  5  0.719626     0.388174  0.913320\n",
       "5 1  0.654206     0.422594  0.874119\n",
       "  2  0.663551     0.451512  0.870941\n",
       "  5  0.700935     0.435951  0.880581"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glass_train_df = pd.read_csv(\"glass_train.txt\")\n",
    "\n",
    "glass_test_df = pd.read_csv(\"glass_test.txt\")\n",
    "\n",
    "forest_model = DecisionForest()\n",
    "\n",
    "test_labels = glass_test_df[\"CLASS\"]\n",
    "\n",
    "min_samples_split_values = [1,2,5]\n",
    "random_features_values = [1,2,5]\n",
    "\n",
    "parameters = [(min_samples_split,random_features) for min_samples_split in min_samples_split_values \n",
    "              for random_features in random_features_values]\n",
    "\n",
    "results = np.empty((len(parameters),3))\n",
    "\n",
    "for i in range(len(parameters)):\n",
    "    t0 = time.perf_counter()\n",
    "    forest_model.fit(glass_train_df,min_samples_split=parameters[i][0],random_features=parameters[i][1])\n",
    "    print(\"Training time {0}: {1:.2f} s.\".format(parameters[i],time.perf_counter()-t0))\n",
    "    t0 = time.perf_counter()\n",
    "    predictions = forest_model.predict(glass_test_df)\n",
    "    print(\"Testing time {0}: {1:.2f} s.\".format(parameters[i],time.perf_counter()-t0))\n",
    "    results[i] = [accuracy(predictions,test_labels),brier_score(predictions,test_labels),\n",
    "                  auc(predictions,test_labels)] # Assuming that you have defined auc - remove otherwise\n",
    "\n",
    "results = pd.DataFrame(results,index=pd.MultiIndex.from_product([min_samples_split_values,random_features_values]),\n",
    "                       columns=[\"Accuracy\",\"Brier score\",\"AUC\"])\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Henrik's result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time (1, 1): 7.51 s.\n",
      "Testing time (1, 1): 0.09 s.\n",
      "Training time (1, 2): 10.65 s.\n",
      "Testing time (1, 2): 0.09 s.\n",
      "Training time (1, 5): 19.78 s.\n",
      "Testing time (1, 5): 0.09 s.\n",
      "Training time (2, 1): 7.97 s.\n",
      "Testing time (2, 1): 0.09 s.\n",
      "Training time (2, 2): 12.01 s.\n",
      "Testing time (2, 2): 0.10 s.\n",
      "Training time (2, 5): 19.42 s.\n",
      "Testing time (2, 5): 0.10 s.\n",
      "Training time (5, 1): 4.57 s.\n",
      "Testing time (5, 1): 0.10 s.\n",
      "Training time (5, 2): 7.31 s.\n",
      "Testing time (5, 2): 0.09 s.\n",
      "Training time (5, 5): 9.75 s.\n",
      "Testing time (5, 5): 0.09 s.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Brier score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>0.644860</td>\n",
       "      <td>0.477912</td>\n",
       "      <td>0.860736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.710280</td>\n",
       "      <td>0.411981</td>\n",
       "      <td>0.892842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.710280</td>\n",
       "      <td>0.421511</td>\n",
       "      <td>0.895716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2</th>\n",
       "      <th>1</th>\n",
       "      <td>0.663551</td>\n",
       "      <td>0.452421</td>\n",
       "      <td>0.872447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.626168</td>\n",
       "      <td>0.411684</td>\n",
       "      <td>0.911137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.654206</td>\n",
       "      <td>0.435847</td>\n",
       "      <td>0.881621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">5</th>\n",
       "      <th>1</th>\n",
       "      <td>0.644860</td>\n",
       "      <td>0.457859</td>\n",
       "      <td>0.865636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.719626</td>\n",
       "      <td>0.410616</td>\n",
       "      <td>0.903016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.616822</td>\n",
       "      <td>0.455782</td>\n",
       "      <td>0.883897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Accuracy  Brier score       AUC\n",
       "1 1  0.644860     0.477912  0.860736\n",
       "  2  0.710280     0.411981  0.892842\n",
       "  5  0.710280     0.421511  0.895716\n",
       "2 1  0.663551     0.452421  0.872447\n",
       "  2  0.626168     0.411684  0.911137\n",
       "  5  0.654206     0.435847  0.881621\n",
       "5 1  0.644860     0.457859  0.865636\n",
       "  2  0.719626     0.410616  0.903016\n",
       "  5  0.616822     0.455782  0.883897"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glass_train_df = pd.read_csv(\"glass_train.txt\")\n",
    "\n",
    "glass_test_df = pd.read_csv(\"glass_test.txt\")\n",
    "\n",
    "forest_model = DecisionForest()\n",
    "\n",
    "test_labels = glass_test_df[\"CLASS\"]\n",
    "\n",
    "min_samples_split_values = [1,2,5]\n",
    "random_features_values = [1,2,5]\n",
    "\n",
    "parameters = [(min_samples_split,random_features) for min_samples_split in min_samples_split_values \n",
    "              for random_features in random_features_values]\n",
    "\n",
    "results = np.empty((len(parameters),3))\n",
    "\n",
    "for i in range(len(parameters)):\n",
    "    t0 = time.perf_counter()\n",
    "    forest_model.fit(glass_train_df,min_samples_split=parameters[i][0],random_features=parameters[i][1])\n",
    "    print(\"Training time {0}: {1:.2f} s.\".format(parameters[i],time.perf_counter()-t0))\n",
    "    t0 = time.perf_counter()\n",
    "    predictions = forest_model.predict(glass_test_df)\n",
    "    print(\"Testing time {0}: {1:.2f} s.\".format(parameters[i],time.perf_counter()-t0))\n",
    "    results[i] = [accuracy(predictions,test_labels),brier_score(predictions,test_labels),\n",
    "                  auc(predictions,test_labels)] # Assuming that you have defined auc - remove otherwise\n",
    "\n",
    "results = pd.DataFrame(results,index=pd.MultiIndex.from_product([min_samples_split_values,random_features_values]),\n",
    "                       columns=[\"Accuracy\",\"Brier score\",\"AUC\"])\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.97\n",
      "AUC on training set: 1.00\n",
      "Brier score on training set: 0.11\n"
     ]
    }
   ],
   "source": [
    "train_labels = glass_train_df[\"CLASS\"]\n",
    "forest_model.fit(glass_train_df,min_samples_split=1)\n",
    "predictions = forest_model.predict(glass_train_df)\n",
    "print(\"Accuracy on training set: {0:.2f}\".format(accuracy(predictions,train_labels)))\n",
    "print(\"AUC on training set: {0:.2f}\".format(auc(predictions,train_labels)))\n",
    "print(\"Brier score on training set: {0:.2f}\".format(brier_score(predictions,train_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment on assumptions, things that do not work properly, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We made every algorithm correctly.\n",
    "As it is random, and test case is really small, accuracy and other metrics are different in every trial.\n",
    "\n",
    "We marked new logics in random forest with ##### line"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
